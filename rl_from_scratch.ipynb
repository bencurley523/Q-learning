{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    '''\n",
    "    init params:\n",
    "        grid_size (int) - side length of grid\n",
    "        player_pos (list as in [x, y]) - starting player pos\n",
    "        obstacles (list of tuples as in [(o1r, o1c), (o2r, o2c)...]) - positions of all obstacles\n",
    "        holes (list of tuples as in [(h1r, h1c), (h2r, h2c)...]) - positions of all holes\n",
    "        bonuses (list of tuples as in [(b1r, b1c), (b2r, b2c)...]) - positions of all bonuses\n",
    "    '''\n",
    "    def __init__(self, grid_size = 5, player_pos = None, obstacles = [(2, 3)], holes = [(3, 1)], bonuses = [(0, 0)]):\n",
    "        self.grid_size = grid_size\n",
    "        if not player_pos:\n",
    "            self.player_pos = [self.grid_size-1, 0]\n",
    "            self.starting_player_pos = self.player_pos.copy()\n",
    "        else:\n",
    "            self.player_pos = player_pos\n",
    "            self.starting_player_pos = self.player_pos.copy()\n",
    "        self.obstacles = obstacles\n",
    "        self.holes = holes\n",
    "        self.start_bonuses = bonuses.copy()\n",
    "        self.bonuses = bonuses\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        resets environment with deault params\n",
    "\n",
    "        returns:\n",
    "        state - list describing player position in form [row, col]\n",
    "        '''\n",
    "        self.__init__(player_pos=self.starting_player_pos, bonuses=self.start_bonuses)\n",
    "        return self.player_pos\n",
    "\n",
    "    def update(self, action):\n",
    "        '''\n",
    "        updates environment with action\n",
    "        returns: (done, observation, reward)\n",
    "        '''\n",
    "        if not self.done:\n",
    "            reward = -1\n",
    "            self.player_pos[0] -= action[1]\n",
    "            self.player_pos[1] += action[0]\n",
    "            if tuple(self.player_pos) in self.obstacles:\n",
    "                self.player_pos[0] += action[1]\n",
    "                self.player_pos[1] -= action[0]\n",
    "            elif (tuple(self.player_pos)[0] > self.grid_size-1) or (tuple(self.player_pos)[0] < 0) or (tuple(self.player_pos)[1] > self.grid_size-1) or (tuple(self.player_pos)[1] < 0):\n",
    "                self.player_pos[0] += action[1]\n",
    "                self.player_pos[1] -= action[0]\n",
    "            elif tuple(self.player_pos) in self.bonuses:\n",
    "                reward = 1\n",
    "                self.bonuses.remove(tuple(self.player_pos))\n",
    "            elif tuple(self.player_pos) in self.holes:\n",
    "                reward = -100\n",
    "                self.done = True\n",
    "            elif tuple(self.player_pos) == (0, self.grid_size-1):\n",
    "                self.done = True\n",
    "            return self.done, tuple(self.player_pos), reward\n",
    "        else:\n",
    "            print('\\033[1;32mEpisode is done, reset environment')\n",
    "            return self.done, tuple(self.player_pos), 0\n",
    "\n",
    "    def render(self):\n",
    "        '''\n",
    "        renders environment as string\n",
    "        '''\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if (i, j) == tuple(self.player_pos):\n",
    "                    print('[\\033[1;36mX\\033[1;37m]', end='')\n",
    "                elif (i, j) in self.obstacles:\n",
    "                    print('[#]', end='')\n",
    "                elif (i, j) in self.holes:\n",
    "                    print('[\\033[1;31mO\\033[1;37m]', end='')\n",
    "                elif (i, j) in self.bonuses:\n",
    "                    print('[\\033[1;33m*\\033[1;37m]', end='')\n",
    "                elif (i, j) == (0, self.grid_size-1):\n",
    "                    print('[\\033[1;32mG\\033[1;37m]', end='')\n",
    "                else:\n",
    "                    print('\\033[1;37m[ ]', end='')\n",
    "            print()\n",
    "\n",
    "    def state_to_frame(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        frame = ''\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if (i, j) == tuple(self.player_pos):\n",
    "                    frame += '[\\033[1;36mX\\033[1;37m]'\n",
    "                elif (i, j) in self.obstacles:\n",
    "                    frame += '[#]'\n",
    "                elif (i, j) in self.holes:\n",
    "                    frame += '[\\033[1;31mO\\033[1;37m]'\n",
    "                elif (i, j) in self.bonuses:\n",
    "                    frame += '[\\033[1;33m*\\033[1;37m]'\n",
    "                elif (i, j) == (0, self.grid_size-1):\n",
    "                    frame += '[\\033[1;32mG\\033[1;37m]'\n",
    "                else:\n",
    "                    frame += '\\033[1;37m[ ]'\n",
    "            frame += '\\n'\n",
    "        return frame\n",
    "\n",
    "    def player_input(self):\n",
    "        '''\n",
    "        asks for and processes player input\n",
    "        returns: action\n",
    "        '''\n",
    "        player_in = input('Input: up, down, left, right')\n",
    "        action = ()\n",
    "        while player_in not in ['up', 'down', 'left', 'right']:\n",
    "            player_in = input('Input not valid\\nInput: up, down, left, right')\n",
    "        if player_in == 'up':\n",
    "            action = (0, 1)\n",
    "        elif player_in == 'down':\n",
    "            action = (0, -1)\n",
    "        elif player_in == 'left':\n",
    "            action = (-1, 0)\n",
    "        elif player_in == 'right':\n",
    "            action = (1, 0)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.Q_table = [[{'up': 0, 'down': 0, 'left': 0, 'right': 0} for col in range(env.grid_size)] for row in range(env.grid_size)]\n",
    "        self.base = 1\n",
    "\n",
    "    def update_Q_value(self, reward, prev_pos, cur_pos, last_action, discount_factor=.9):\n",
    "        '''\n",
    "        params:\n",
    "        reward - reward earned from taking last action\n",
    "        cur_pos - position after taking last action\n",
    "        last_action - last action taken\n",
    "        discount_factor - factor that discounts rewards earned later, default is .9\n",
    "\n",
    "        updates Q-value for state, action pair as mean of old and new Q-values\n",
    "        '''\n",
    "        #prev_pos = [cur_pos[0]+last_action[1], cur_pos[1]-last_action[0]]\n",
    "        next_state_q_values = self.Q_table[cur_pos[0]][cur_pos[1]]\n",
    "        next_action_sum = 0\n",
    "        prob_dist = self.make_probability_distribution(cur_pos)\n",
    "        for next_action in self.Q_table[cur_pos[0]][cur_pos[1]]:\n",
    "            next_action_sum += prob_dist[next_action]*self.Q_table[cur_pos[0]][cur_pos[1]][next_action]\n",
    "        new_q_val = reward + discount_factor*next_action_sum\n",
    "        action_to_word = {(0, 1): 'up', (0, -1): 'down', (-1, 0): 'left', (1, 0): 'right'}\n",
    "        old_q_val = self.Q_table[prev_pos[0]][prev_pos[1]][action_to_word[last_action]]\n",
    "        self.Q_table[prev_pos[0]][prev_pos[1]][action_to_word[last_action]] = (new_q_val+old_q_val)/2\n",
    "        \n",
    "    def make_probability_distribution(self, state):\n",
    "        '''\n",
    "        param:\n",
    "        state - list describing player position in form [row, col]\n",
    "\n",
    "        returns:\n",
    "        probability distribution - dictionary in the form {'up': p_up, 'down': p_down, 'left': p_left, 'right': p_right}\n",
    "        '''\n",
    "        prob_dist = {'up': 0, 'down': 0, 'left': 0, 'right': 0}\n",
    "        q_sum = 0\n",
    "        for action in prob_dist:\n",
    "            q_sum += self.base**self.Q_table[state[0]][state[1]][action]\n",
    "        for action in prob_dist:\n",
    "            prob_dist[action] = self.base**self.Q_table[state[0]][state[1]][action]/q_sum\n",
    "        return prob_dist\n",
    "    \n",
    "    def predict(self, state):\n",
    "        '''\n",
    "        param:\n",
    "        state - list describing player position in form [row, col]\n",
    "\n",
    "        returns:\n",
    "        action - predicted best action by the model\n",
    "        \n",
    "        predict best action from state\n",
    "        '''\n",
    "        prob_dist = self.make_probability_distribution(state)\n",
    "        index_to_action = {0: (0, 1), 1: (0, -1), 2: (-1, 0), 3: (1, 0)}\n",
    "        to_use = [0, 0, 0, 0]\n",
    "        cur_sum = 0\n",
    "        for i, p in enumerate(list(prob_dist.values())):\n",
    "            cur_sum += p\n",
    "            to_use[i] = cur_sum\n",
    "        rand_num = random()\n",
    "        for i, p in enumerate(to_use):\n",
    "            if rand_num <= p:\n",
    "                return index_to_action[i]\n",
    "    \n",
    "    def update_base(self, inc):\n",
    "        '''\n",
    "        increases the base (b) used for generating probability disributions\n",
    "\n",
    "        given two actions, A and C, with Q-values a and c, respectively - action A will be b^(a-c) times as likely as action C\n",
    "\n",
    "        param:\n",
    "        inc - amount to increase the base by\n",
    "        '''\n",
    "        self.base += inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;33m*\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][\u001b[1;32mG\u001b[1;37m]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][#]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ][\u001b[1;31mO\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "[\u001b[1;36mX\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n"
     ]
    }
   ],
   "source": [
    "env = Game()\n",
    "env.reset()\n",
    "env.render()\n",
    "agent = Agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1 complete\n",
      "episode 2 complete\n",
      "episode 3 complete\n",
      "...\n",
      "episode 10000 complete\n"
     ]
    }
   ],
   "source": [
    "frames = {}\n",
    "for episode in range(10000):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    last_state = state\n",
    "    frames[episode+1] = [(env.state_to_frame(), 0)]\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = agent.predict(state)\n",
    "        done, state, reward = env.update(action)\n",
    "        agent.update_Q_value(reward, last_state, state, action)\n",
    "        last_state = state\n",
    "        score += reward\n",
    "        agent.update_base(.01)\n",
    "        frames[episode+1].append((env.state_to_frame(), reward))\n",
    "    print(f'episode {episode+1} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1000\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][\u001b[1;36mX\u001b[1;37m]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][#]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ][\u001b[1;31mO\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "reward: -1\n"
     ]
    }
   ],
   "source": [
    "for frame, reward in frames[10000]:\n",
    "    print(f'episode: 1000\\n{frame}reward: {reward}')\n",
    "    sleep(.2)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 17\n",
      "[\u001b[1;33m*\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][\u001b[1;32mG\u001b[1;37m]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ][\u001b[1;36mX\u001b[1;37m][#]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ][\u001b[1;31mO\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "reward: -1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bpcur\\OneDrive - Byram Hills Central School District\\JupNotes\\rl_from_scratch.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bpcur/OneDrive%20-%20Byram%20Hills%20Central%20School%20District/JupNotes/rl_from_scratch.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m frame, reward \u001b[39min\u001b[39;00m frames[episode]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bpcur/OneDrive%20-%20Byram%20Hills%20Central%20School%20District/JupNotes/rl_from_scratch.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mframe\u001b[39m}\u001b[39;00m\u001b[39mreward: \u001b[39m\u001b[39m{\u001b[39;00mreward\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bpcur/OneDrive%20-%20Byram%20Hills%20Central%20School%20District/JupNotes/rl_from_scratch.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     sleep(\u001b[39m.1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bpcur/OneDrive%20-%20Byram%20Hills%20Central%20School%20District/JupNotes/rl_from_scratch.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in frames:\n",
    "    for frame, reward in frames[episode]:\n",
    "        print(f'episode: {episode}\\n{frame}reward: {reward}')\n",
    "        sleep(.1)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'up': -4.13126379206069,\n",
       "   'down': -3.5484342912167746,\n",
       "   'left': -4.136625519591362,\n",
       "   'right': -3.447911610818853},\n",
       "  {'up': -3.4481905274514353,\n",
       "   'down': -4.1340777030045635,\n",
       "   'left': -4.332170973552806,\n",
       "   'right': -2.7146850782856173},\n",
       "  {'up': -2.7148656953631867,\n",
       "   'down': -3.4721017653885315,\n",
       "   'left': -3.5384548184296216,\n",
       "   'right': -1.9018366553460935},\n",
       "  {'up': -1.9020797980458197,\n",
       "   'down': -2.7075419435788293,\n",
       "   'left': -2.744123520853549,\n",
       "   'right': -1.0},\n",
       "  {'up': 0, 'down': 0, 'left': 0, 'right': 0}],\n",
       " [{'up': -2.5127872516420426,\n",
       "   'down': -4.6930189666653455,\n",
       "   'left': -4.324917669937912,\n",
       "   'right': -4.101659609754959},\n",
       "  {'up': -3.448239363461256,\n",
       "   'down': -4.856712726218718,\n",
       "   'left': -4.684476720829288,\n",
       "   'right': -3.443769376200086},\n",
       "  {'up': -2.714879485937714,\n",
       "   'down': -4.122216157607167,\n",
       "   'left': -4.062915502052766,\n",
       "   'right': -2.7146782906855904},\n",
       "  {'up': -1.9020257901783266,\n",
       "   'down': -2.7640648991257715,\n",
       "   'left': -2.7085041650434505,\n",
       "   'right': -1.9017109726042847},\n",
       "  {'up': -1.0,\n",
       "   'down': -2.7269287218945126,\n",
       "   'left': -2.649774306853841,\n",
       "   'right': -1.9525095189992903}],\n",
       " [{'up': -3.6937069606510753,\n",
       "   'down': -5.737013319714006,\n",
       "   'left': -4.764536019735332,\n",
       "   'right': -4.695581032044019},\n",
       "  {'up': -4.103684299922692,\n",
       "   'down': -50.0,\n",
       "   'left': -5.194112374365623,\n",
       "   'right': -4.105491764107534},\n",
       "  {'up': -3.44381240068788,\n",
       "   'down': -4.607863916053555,\n",
       "   'left': -4.710483168107087,\n",
       "   'right': -4.200078432081018},\n",
       "  {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       "  {'up': -1.9320383365975418,\n",
       "   'down': -3.636936324134184,\n",
       "   'left': -2.9699833045042925,\n",
       "   'right': -2.955080533772021}],\n",
       " [{'up': -4.545766026470765,\n",
       "   'down': -6.060232435357633,\n",
       "   'left': -5.677204541725985,\n",
       "   'right': -50.0},\n",
       "  {'up': 0, 'down': 0, 'left': 0, 'right': 0},\n",
       "  {'up': -4.323464387950477,\n",
       "   'down': -5.220274738343053,\n",
       "   'left': -50.0,\n",
       "   'right': -4.445163586162173},\n",
       "  {'up': -4.4215932283192885,\n",
       "   'down': -4.803914165745541,\n",
       "   'left': -4.609785834110234,\n",
       "   'right': -3.5832337243035965},\n",
       "  {'up': -2.7949307435041577,\n",
       "   'down': -4.419763084189686,\n",
       "   'left': -4.3795490695927395,\n",
       "   'right': -3.76520385214058}],\n",
       " [{'up': -4.6934610492325675,\n",
       "   'down': -5.453378950158021,\n",
       "   'left': -5.734359060475596,\n",
       "   'right': -6.4680670108486575},\n",
       "  {'up': -50.0,\n",
       "   'down': -6.6198259347051245,\n",
       "   'left': -5.70168597699084,\n",
       "   'right': -6.198450610487585},\n",
       "  {'up': -5.022274345298588,\n",
       "   'down': -5.6199074050081315,\n",
       "   'left': -6.2718100216275605,\n",
       "   'right': -5.139491167743613},\n",
       "  {'up': -4.37829493279078,\n",
       "   'down': -5.191444452630936,\n",
       "   'left': -5.23270681165787,\n",
       "   'right': -4.622753446441875},\n",
       "  {'up': -3.76943698002936,\n",
       "   'down': -4.0891119157553355,\n",
       "   'left': -4.725648566111005,\n",
       "   'right': -4.4153208678427465}]]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.Q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(random()*10)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_env = Game(grid_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;33m*\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][\u001b[1;32mG\u001b[1;37m]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ][#]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ][\u001b[1;31mO\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "[\u001b[1;36mX\u001b[1;37m]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n",
      "\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\u001b[1;37m[ ]\n"
     ]
    }
   ],
   "source": [
    "large_env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
